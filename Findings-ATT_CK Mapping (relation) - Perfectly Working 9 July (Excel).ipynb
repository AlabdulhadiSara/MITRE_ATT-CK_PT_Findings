{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gzip\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import urllib  \n",
    "import re  \n",
    "import nltk\n",
    "import gensim\n",
    "\n",
    "from sklearn.manifold import TSNE, MDS, Isomap\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyxll import xl_func\n",
    "\n",
    "from gensim.models import Doc2Vec\n",
    "import gensim.models.doc2vec\n",
    "from collections import OrderedDict\n",
    "import multiprocessing\n",
    "\n",
    "from stix2 import FileSystemSource\n",
    "from stix2 import Filter\n",
    "\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#replace_dots: get rid of any extension '.'s so they are not interpreted as full-stops\n",
    "def remove_citations(text):\n",
    "    text = re.sub(r'\\(Citations?: \\S+\\)', '', text)\n",
    "    return text\n",
    "\n",
    "def remove_urls(text):\n",
    "    text = re.sub(r'\\[?\\S+\\]?\\(?https?://\\S+\\)?', '', text)\n",
    "    return text\n",
    "\n",
    "def replace_dots(text):\n",
    "    try:\n",
    "        ind = text.index('.')\n",
    "        while ind < len(text)-1:\n",
    "            if not text[ind+1:ind+2] == ' ' and not text[ind+1:ind+2] == '\"' and not text[ind+1:ind+2] == '\\'':\n",
    "                text = text[:ind] + '_' + text[ind+1:]\n",
    "            try:\n",
    "                ind = ind+1 + text[ind+1:].index('.')\n",
    "            except:\n",
    "                break\n",
    "        return text\n",
    "    except:\n",
    "        return text\n",
    "\n",
    "def remove_patterns(text):\n",
    "    text = re.sub(r'\\[?\\S+\\]?\\(?[A-Za-z]?:\\S+\\)?', '', text)\n",
    "    return text\n",
    "\n",
    "def remove_snips(text):\n",
    "    text = re.sub(r'/[\\-*]{2,}(.*)[\\-*]{2,}/s', '', text)\n",
    "    return text\n",
    "\n",
    "def remove_ipaddresses(text):\n",
    "    text = re.sub(r'\\b\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\b', '', text)\n",
    "    return text\n",
    "\n",
    "def remove_chars(text):\n",
    "    to_remove = \"This technique has been deprecated. Please see ATT&CK's Initial Access and Execution tactics for replacement techniques.\"\n",
    "    text = text.replace(to_remove,'')\n",
    "    text = re.sub('<[^>]*>', '', text.lower()).strip()\n",
    "    text = re.sub('[^a-zA-Z\\'\\_]', ' ', text.lower())\n",
    "    return text\n",
    "\n",
    "#clean up the text\n",
    "def clean_text(text):\n",
    "    clean = remove_citations(text)\n",
    "    clean = remove_urls(clean)\n",
    "    clean = replace_dots(clean)\n",
    "    clean = remove_patterns(clean)\n",
    "    clean = remove_snips(clean)\n",
    "    clean = remove_ipaddresses(clean)\n",
    "    clean = remove_chars(clean)\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "##Extract MITRE Data\n",
    "\n",
    "fs = FileSystemSource('C:\\pyxll\\enterprise-attack')\n",
    "filt1 = Filter('type', '=', 'relationship')\n",
    "techniques_ent1 = fs.query([filt1])\n",
    "\n",
    "fs = FileSystemSource('C:\\pyxll\\pre-attack')\n",
    "filt1 = Filter('type', '=', 'relationship')\n",
    "techniques_pre1 = fs.query([filt1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "##Clean MITRE Data\n",
    "\n",
    "ent_dict1 = {obj['id']: (obj['relationship_type'],\n",
    "                         (obj.get('description') or 'Nan' )\n",
    "                         obj['target_ref']) for obj in techniques_ent1\n",
    "             if obj['relationship_type'] == 'uses'}\n",
    "pre_dict1 = {obj['id']: (obj['relationship_type'],\n",
    "                         (obj.get('description') or 'Nan' ),\n",
    "                         obj['target_ref']) for obj in techniques_pre1\n",
    "             if obj['relationship_type'] == 'uses'}\n",
    "\n",
    "ent_dict1 = {k:v for k,v in ent_dict1.items() if not 'Nan' in v}\n",
    "pre_dict1 = {k:v for k,v in pre_dict1.items() if not 'Nan' in v}\n",
    "\n",
    "ent_df1 = pd.DataFrame({'relationship_id':tuple(ent_dict1.keys()),\n",
    "                        'values': tuple(ent_dict1.values())})\n",
    "pre_df1 = pd.DataFrame({'relationship_id':tuple(pre_dict1.keys()),\n",
    "                        'values': tuple(pre_dict1.values())})\n",
    "\n",
    "ent_df1['type'] = ['ent_attack']*ent_df1.shape[0]\n",
    "pre_df1['type'] = ['pre_attack']*pre_df1.shape[0]\n",
    "\n",
    "techniques_df1 = pd.concat([ent_df1, pre_df1], ignore_index=True)\n",
    "techniques_df1['relationship'] = techniques_df1['values'].apply(\n",
    "    lambda x: x[0].strip())\n",
    "techniques_df1['relation_description'] = techniques_df1['values'].apply(\n",
    "    lambda x: x[1].strip())\n",
    "techniques_df1['attack_id'] = techniques_df1['values'].apply(\n",
    "    lambda x: x[2].strip())\n",
    "techniques_df1['cleanText'] = techniques_df1['relation_description'].apply(\n",
    "    lambda x: clean_text(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_zip1 = list(zip(techniques_df1['relationship_id'],techniques_df1['relation_description']))\n",
    "final_dict1 = {key:value for key,value in all_zip1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 2:\n",
    "            nltk.bigrams(token)\n",
    "            result.append(token)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "##Create named tuples for gensim\n",
    "\n",
    "Document = namedtuple('TaggedDocument', 'words tags object_type')\n",
    "\n",
    "alldocs1 = []\n",
    "for row_id, row in zip(techniques_df1['relationship_id'],techniques_df1[\n",
    "    'cleanText']):\n",
    "    words = preprocess(row)\n",
    "    tags = [row_id]\n",
    "    object_type = 'Relationship'\n",
    "    alldocs1.append(Document(words, tags, object_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "assert gensim.models.doc2vec.FAST_VERSION > -1,\n",
    "\"This will be painfully slow otherwise\"\n",
    "\n",
    "model = Doc2Vec(dm=0, vector_size=100, negative=5, hs=0,\n",
    "                min_count=10, sample=0, epochs=100, workers=cores)\n",
    "\n",
    "model.build_vocab(alldocs1)\n",
    "\n",
    "from random import shuffle\n",
    "doc_list1 = alldocs1[:]  \n",
    "shuffle(doc_list1)\n",
    "    \n",
    "model.train(doc_list1, total_examples=len(doc_list1), epochs=model.epochs)\n",
    "word_models = simple_models[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "@xl_func\n",
    "def find_most_similar_relation(finding):\n",
    "    result = model.docvecs.most_similar(positive=[\n",
    "        model.infer_vector(finding)],topn=1)\n",
    "    return result[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs1 = FileSystemSource('C:\\pyxll\\enterprise-attack')\n",
    "filt1 = Filter('type', '=', 'relationship')\n",
    "techniques_ent1 = fs.query([filt1])\n",
    "\n",
    "fs2 = FileSystemSource('C:\\pyxll\\pre-attack')\n",
    "filt1 = Filter('type', '=', 'relationship')\n",
    "techniques_pre1 = fs.query([filt1])\n",
    "\n",
    "def get_technique_by_name(src, name):\n",
    "    filt = [\n",
    "        Filter('type', '=', 'attack-pattern'),\n",
    "        Filter('id', '=', name)\n",
    "    ]\n",
    "    return src.query(filt)\n",
    "\n",
    "@xl_func\n",
    "def get_relation_desc(finding):\n",
    "    relation = find_most_similar_relation(finding)\n",
    "    for j in range(len(techniques_df1['relationship_id'])):\n",
    "        if relation == str(techniques_df1['relationship_id'][j]):\n",
    "            desc = str(techniques_df1['relation_description'][j])\n",
    "    return desc\n",
    "\n",
    "@xl_func       \n",
    "def get_attack(finding):\n",
    "    relation = find_most_similar_relation(finding)\n",
    "    for j in range(len(techniques_df1['relationship_id'])):\n",
    "        if relation == str(techniques_df1['relationship_id'][j]):\n",
    "            attack_object = get_technique_by_name(fs1, techniques_df1['attack_id'][j])\n",
    "            if not attack_object:\n",
    "                attack_object = get_technique_by_name(fs2, techniques_df1['attack_id'][j])\n",
    "    return attack_object\n",
    "\n",
    "@xl_func\n",
    "def get_attack_id(finding):\n",
    "    relation = find_most_similar_relation(finding)\n",
    "    for j in range(len(techniques_df1['relationship_id'])):\n",
    "        if relation == str(techniques_df1['relationship_id'][j]):\n",
    "            attack_object = get_technique_by_name(fs1, techniques_df1['attack_id'][j])\n",
    "            if not attack_object:\n",
    "                attack_object = get_technique_by_name(fs2, techniques_df1['attack_id'][j])\n",
    "            external_ref = attack_object[0].get('external_references')\n",
    "            external_id = external_ref[0]['external_id']\n",
    "    return external_id\n",
    "\n",
    "@xl_func\n",
    "def get_attack_name(finding):\n",
    "    relation = find_most_similar_relation(finding)\n",
    "    for j in range(len(techniques_df1['relationship_id'])):\n",
    "        if relation == str(techniques_df1['relationship_id'][j]):\n",
    "            attack_object = get_technique_by_name(fs1, techniques_df1['attack_id'][j])\n",
    "            if not attack_object:\n",
    "                attack_object = get_technique_by_name(fs2, techniques_df1['attack_id'][j])\n",
    "            name = attack_object[0].get('name')\n",
    "    return name\n",
    "\n",
    "@xl_func\n",
    "def get_phase(finding):\n",
    "    relation = find_most_similar_relation(finding)\n",
    "    for j in range(len(techniques_df1['relationship_id'])):\n",
    "        if relation == str(techniques_df1['relationship_id'][j]):\n",
    "            attack_object = get_technique_by_name(fs1, techniques_df1['attack_id'][j])\n",
    "            if not attack_object:\n",
    "                attack_object = get_technique_by_name(fs2, techniques_df1['attack_id'][j])\n",
    "            phase = attack_object[0]['kill_chain_phases'][0]['phase_name']\n",
    "    return phase"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
